{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from lib.exceptions import CustomException\n",
    "from lib.logger import logging\n",
    "from src.preprocessing import DataTransformation\n",
    "from src.preprocessing import DataTransformationConfig\n",
    "\n",
    "from src.components.model_trainer import ModelTrainerConfig\n",
    "from src.components.model_trainer import ModelTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Replace these values with your actual credentials\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'jogesh',\n",
    "    'password': 'Jogesh_295',\n",
    "    'database': 'coordinates_data',\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Establish a connection to the MySQL server\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "\n",
    "    # Create a cursor object to interact with the database\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Check and update user permissions\n",
    "    #cursor.execute(f\"GRANT ALL PRIVILEGES ON {db_config['database']}.* TO '{db_config['user']}'@'{db_config['host']}' IDENTIFIED BY '{db_config['password']}';\")\n",
    "\n",
    "    # Commit the changes to the server\n",
    "    connection.commit()\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    print(\"Connection successful!\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error connecting to MySQL: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest  and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mysql-connector-python\n",
    "# use above code if not mysql connector in not installed\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, folder_path, host, user, password, database, table):\n",
    "        self.folder_path = folder_path\n",
    "        self.host = host\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.database = database\n",
    "        self.table = table\n",
    "\n",
    "    def ingest_data(self):\n",
    "        try:\n",
    "            # Connect to the MySQL database\n",
    "            connection = mysql.connector.connect(\n",
    "                host=self.host,\n",
    "                user=self.user,\n",
    "                password=self.password,\n",
    "                database=self.database\n",
    "            )\n",
    "            cursor = connection.cursor()\n",
    "\n",
    "            # Execute a query to fetch data from the specified table\n",
    "            query = f\"SELECT * FROM {self.table}\"\n",
    "            cursor.execute(query)\n",
    "\n",
    "            # Fetch all the rows\n",
    "            data = cursor.fetchall()\n",
    "\n",
    "            # Get column names from the cursor description\n",
    "            column_names = [desc[0] for desc in cursor.description]\n",
    "\n",
    "            # Create a DataFrame from the fetched data\n",
    "            df = pd.DataFrame(data, columns=column_names)\n",
    "            train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Store the DataFrame as CSV in the specified folder\n",
    "            os.makedirs(self.folder_path, exist_ok=True)\n",
    "            file_path = os.path.join(self.folder_path, 'data.csv')\n",
    "            train_path = os.path.join(self.folder_path, 'train.csv')\n",
    "            test_path = os.path.join(self.folder_path, 'test.csv')\n",
    "            df.to_csv(file_path, index=False)\n",
    "            train_set.to_csv(train_path, index=False)\n",
    "            test_set.to_csv(test_path, index=False)\n",
    "\n",
    "            print(\"Data ingestion completed successfully.\")\n",
    "\n",
    "        except mysql.connector.Error as e:\n",
    "            print(f\"Error connecting to MySQL: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = '.\\data\\raw_data'\n",
    "    host = 'localhost'\n",
    "    user = 'jogesh'\n",
    "    password = 'Jogesh_295'\n",
    "    database = 'coordinates_data'\n",
    "    table = 'coordinates_table'\n",
    "\n",
    "    data_ingestion_instance = DataIngestion(folder_path, host, user, password, database, table)\n",
    "    data_ingestion_instance.ingest_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lib.utils import save_pkl_object\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "class CustomException(Exception):\n",
    "    pass\n",
    "\n",
    "class Preprocessing:\n",
    "    def __init__(self, scaler=StandardScaler()):\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def preprocess(self, X_train, y_train, X_test, y_test):\n",
    "        # Standard scaling on X_train and X_test\n",
    "        scaled_X_train = self.scaler.fit_transform(X_train)\n",
    "        scaled_X_test = self.scaler.transform(X_test)\n",
    "\n",
    "        return scaled_X_train, y_train, scaled_X_test, y_test\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined as DataFrames\n",
    "\n",
    "preprocessor = Preprocessing()\n",
    "\n",
    "scaled_X_train, y_train, scaled_X_test, y_test = preprocessor.preprocess(X_train, y_train, X_test, y_test)\n",
    "\n",
    "preprocessor_path = '.\\models\\preprocessor.pkl'\n",
    "\n",
    "preprocessor.save_pkl_object(preprocessor_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
